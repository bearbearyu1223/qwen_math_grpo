{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRPO Training for Qwen2.5-Math-1.5B on Google Colab\n",
    "\n",
    "This notebook demonstrates how to train a math reasoning model using **Group Relative Policy Optimization (GRPO)** on the MATH dataset.\n",
    "\n",
    "## Requirements\n",
    "- Google Colab with GPU (T4 or better, A100 recommended)\n",
    "- ~16GB GPU memory for training\n",
    "\n",
    "## What is GRPO?\n",
    "GRPO (from DeepSeekMath and DeepSeek R1) is a policy gradient method that:\n",
    "1. Generates multiple responses per question\n",
    "2. Computes rewards based on answer correctness\n",
    "3. Normalizes rewards within each group to get advantages\n",
    "4. Trains using policy gradient methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/bearbearyu1223/qwen_math_grpo.git\n",
    "%cd qwen_math_grpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install uv package manager\n!curl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Add uv to PATH (source doesn't work with ! in Colab)\nimport os\nos.environ[\"PATH\"] = f\"{os.environ['HOME']}/.local/bin:{os.environ['PATH']}\"\n\n# Install base dependencies\n!uv sync\n\n# Install vLLM separately (needs system CUDA compatibility)\n!uv pip install vllm>=0.8.4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download the MATH dataset\n!uv run python scripts/download_dataset.py"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset\n",
    "!wc -l data/math/train.jsonl data/math/test.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a sample from the dataset\n",
    "import json\n",
    "\n",
    "with open('data/math/train.jsonl') as f:\n",
    "    sample = json.loads(f.readline())\n",
    "    \n",
    "print(\"Problem:\")\n",
    "print(sample['problem'][:500])\n",
    "print(\"\\nAnswer:\", sample['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run GRPO Training\n",
    "\n",
    "### Training Configuration\n",
    "\n",
    "For Colab with a single GPU, we'll use single-GPU mode. Adjust parameters based on your GPU memory:\n",
    "\n",
    "| GPU | Recommended Settings |\n",
    "|-----|---------------------|\n",
    "| T4 (16GB) | `--rollout-batch-size 8 --train-batch-size 8` |\n",
    "| A100 (40GB) | `--rollout-batch-size 32 --train-batch-size 32` |\n",
    "| A100 (80GB) | `--rollout-batch-size 64 --train-batch-size 64` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Quick test run (5 steps) to verify everything works\n!uv run python scripts/run_grpo.py \\\n    --model-name-or-path Qwen/Qwen2.5-Math-1.5B \\\n    --single-gpu \\\n    --policy-device cuda:0 \\\n    --rollout-batch-size 8 \\\n    --train-batch-size 8 \\\n    --gradient-accumulation-steps 8 \\\n    --n-grpo-steps 5 \\\n    --output-dir outputs/grpo_test"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Full training run (adjust n-grpo-steps based on your time budget)\n!uv run python scripts/run_grpo.py \\\n    --model-name-or-path Qwen/Qwen2.5-Math-1.5B \\\n    --single-gpu \\\n    --policy-device cuda:0 \\\n    --rollout-batch-size 8 \\\n    --train-batch-size 8 \\\n    --gradient-accumulation-steps 8 \\\n    --n-grpo-steps 100 \\\n    --eval-steps 20 \\\n    --save-steps 50 \\\n    --output-dir outputs/grpo_model"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check saved model\n",
    "!ls -la outputs/grpo_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Evaluate the GRPO-trained model\n!uv run python scripts/run_math_eval.py \\\n    --model-name-or-path outputs/grpo_model/final \\\n    --input-path data/math/test.jsonl \\\n    --output-path outputs/grpo_eval_results.jsonl \\\n    --backend transformers \\\n    --num-samples 100"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Evaluate the base model for comparison\n!uv run python scripts/run_math_eval.py \\\n    --model-name-or-path Qwen/Qwen2.5-Math-1.5B \\\n    --input-path data/math/test.jsonl \\\n    --output-path outputs/base_eval_results.jsonl \\\n    --backend transformers \\\n    --num-samples 100"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from statistics import mean\n",
    "\n",
    "def load_results(path):\n",
    "    results = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            results.append(json.loads(line))\n",
    "    return results\n",
    "\n",
    "def compute_metrics(results):\n",
    "    format_rewards = [r['metrics']['format_reward'] for r in results]\n",
    "    answer_rewards = [r['metrics']['answer_reward'] for r in results]\n",
    "    return {\n",
    "        'format_accuracy': mean(format_rewards),\n",
    "        'answer_accuracy': mean(answer_rewards),\n",
    "        'n_samples': len(results)\n",
    "    }\n",
    "\n",
    "# Load and compare results\n",
    "try:\n",
    "    grpo_results = load_results('outputs/grpo_eval_results.jsonl')\n",
    "    base_results = load_results('outputs/base_eval_results.jsonl')\n",
    "    \n",
    "    grpo_metrics = compute_metrics(grpo_results)\n",
    "    base_metrics = compute_metrics(base_results)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"EVALUATION COMPARISON\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"\\n{'Model':<25} {'Format Acc':<15} {'Answer Acc':<15}\")\n",
    "    print(\"-\" * 55)\n",
    "    print(f\"{'Base (Qwen2.5-Math-1.5B)':<25} {base_metrics['format_accuracy']:.2%:<15} {base_metrics['answer_accuracy']:.2%:<15}\")\n",
    "    print(f\"{'GRPO-Trained':<25} {grpo_metrics['format_accuracy']:.2%:<15} {grpo_metrics['answer_accuracy']:.2%:<15}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    improvement = grpo_metrics['answer_accuracy'] - base_metrics['answer_accuracy']\n",
    "    print(f\"\\nImprovement: {improvement:+.2%}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Results file not found: {e}\")\n",
    "    print(\"Make sure to run the evaluation cells above first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View Analysis Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View GRPO model analysis report\n",
    "!cat outputs/grpo_eval_results_analysis.txt | head -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View base model analysis report\n",
    "!cat outputs/base_eval_results_analysis.txt | head -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Model to Google Drive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy trained model to Google Drive\n",
    "!cp -r outputs/grpo_model /content/drive/MyDrive/grpo_model_backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model for interactive testing\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_path = \"outputs/grpo_model/final\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a math problem\n",
    "def solve_math_problem(question):\n",
    "    prompt = f\"\"\"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
    "User: {question}\n",
    "Assistant: <think>\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1024,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Example problem\n",
    "question = \"What is the sum of all positive integers n such that n^2 + n + 1 divides n^4 + 2n^3 + 3n^2 + 2n + 1?\"\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(\"Model's Response:\")\n",
    "print(solve_math_problem(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own math problem\n",
    "your_question = \"If x + y = 10 and xy = 21, what is x^2 + y^2?\"\n",
    "print(f\"Question: {your_question}\\n\")\n",
    "print(\"Model's Response:\")\n",
    "print(solve_math_problem(your_question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "### Training Tips\n",
    "- Start with a small number of steps (5-10) to verify everything works\n",
    "- Monitor GPU memory usage and adjust batch sizes accordingly\n",
    "- Use Weights & Biases for experiment tracking: add `--wandb-project your-project-name`\n",
    "\n",
    "### Expected Results\n",
    "- Base Qwen2.5-Math-1.5B: ~50-60% format accuracy, varies on answer accuracy\n",
    "- After GRPO training: Should see improvement in both format and answer accuracy\n",
    "\n",
    "### Troubleshooting\n",
    "- **OOM Error**: Reduce `--rollout-batch-size` and `--train-batch-size`\n",
    "- **Slow Training**: This is expected on T4; consider using A100 for faster training\n",
    "- **Low Accuracy**: Try more training steps or adjust learning rate"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}